{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgocILxP1sjk"
      },
      "source": [
        "## train model1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAXlALXwnYHl",
        "outputId": "5ae2248c-3a68-42be-824d-7d809c182bc8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.14.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.59.3)\n",
            "Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.0)\n",
            "Requirement already satisfied: keras<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHExuVICw9Dd",
        "outputId": "862ef849-b84e-4fe9-f191-2328fe72913d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P7kuha6WxoqJ"
      },
      "outputs": [],
      "source": [
        "# 設定檔案路徑\n",
        "data_path = \"/content/drive/My Drive/colab/PlantCLEF_Subset/PlantCLEF_Subset/\"\n",
        "train_path = data_path + \"train/\"\n",
        "val_path = data_path + \"val/\"\n",
        "test_path = data_path + \"test/\"\n",
        "label_file = data_path + \"labels.txt\"\n",
        "\n",
        "# 載入標籤\n",
        "with open(label_file, 'r') as file:\n",
        "    labels = [line.strip() for line in file]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVyZ08BsxtOd",
        "outputId": "e785c009-b611-4b8f-f5ea-6ad0c9a7c2e1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['ash',\n",
              " 'beech',\n",
              " 'cattail',\n",
              " 'cedar',\n",
              " 'clover',\n",
              " 'cyprus',\n",
              " 'daisy',\n",
              " 'dandelion',\n",
              " 'dogwood',\n",
              " 'elm',\n",
              " 'fern',\n",
              " 'fig',\n",
              " 'fir',\n",
              " 'juniper',\n",
              " 'maple',\n",
              " 'poison_ivy',\n",
              " 'sweetgum',\n",
              " 'sycamore',\n",
              " 'trout_lily',\n",
              " 'tulip_tree']"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ES26phe-x7fI"
      },
      "outputs": [],
      "source": [
        "# 資料收集\n",
        "def load_data(directory, max_images=100):\n",
        "    data = []\n",
        "    labels = []\n",
        "    for label in os.listdir(directory):\n",
        "        label_path = os.path.join(directory, label)\n",
        "        count = 0\n",
        "        for filename in os.listdir(label_path):\n",
        "            if count >= max_images:\n",
        "                break\n",
        "            img_path = os.path.join(label_path, filename)\n",
        "            img = load_img(img_path, target_size=(224, 224))\n",
        "            img_array = img_to_array(img)\n",
        "            data.append(img_array)\n",
        "            labels.append(label)\n",
        "            count += 1\n",
        "    return np.array(data), np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rLD7uoBMyGYS"
      },
      "outputs": [],
      "source": [
        "# 資料預處理\n",
        "def preprocess_data(data, labels):\n",
        "    data = data.astype('float') / 255.0\n",
        "    labels = LabelEncoder().fit_transform(labels)\n",
        "    labels = to_categorical(labels)\n",
        "    return data, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BdQ-HnsC0Wpc"
      },
      "outputs": [],
      "source": [
        "# 加載訓練和驗證數據\n",
        "X_train, y_train = load_data(train_path)\n",
        "X_val, y_val = load_data(val_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vE84Eldl0Yw0"
      },
      "outputs": [],
      "source": [
        "# 資料預處理\n",
        "X_train, y_train = preprocess_data(X_train, y_train)\n",
        "X_val, y_val = preprocess_data(X_val, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUGqYPhi138t",
        "outputId": "f5d16ad8-1b5e-480c-f60c-dcb82ca5b821"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9406464/9406464 [==============================] - 2s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# 特徵提取 (使用MobileNetV2模型)\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "predictions = Dense(len(labels), activation='softmax')(x)\n",
        "model = Model(inputs=base_model.input, outputs=predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBhdPp9wnYQs",
        "outputId": "fa0870d2-b932-4932-9b4a-d489126fd67f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "63/63 [==============================] - 20s 141ms/step - loss: 2.0536 - accuracy: 0.4095 - val_loss: 2.0917 - val_accuracy: 0.4017\n",
            "Epoch 2/10\n",
            "63/63 [==============================] - 5s 82ms/step - loss: 1.0394 - accuracy: 0.6930 - val_loss: 2.1302 - val_accuracy: 0.4292\n",
            "Epoch 3/10\n",
            "63/63 [==============================] - 6s 92ms/step - loss: 0.6773 - accuracy: 0.8075 - val_loss: 1.9389 - val_accuracy: 0.4485\n",
            "Epoch 4/10\n",
            "63/63 [==============================] - 5s 73ms/step - loss: 0.4226 - accuracy: 0.8990 - val_loss: 2.1283 - val_accuracy: 0.4320\n",
            "Epoch 5/10\n",
            "63/63 [==============================] - 6s 96ms/step - loss: 0.2576 - accuracy: 0.9420 - val_loss: 2.0929 - val_accuracy: 0.4559\n",
            "Epoch 6/10\n",
            "63/63 [==============================] - 6s 89ms/step - loss: 0.1377 - accuracy: 0.9820 - val_loss: 2.1235 - val_accuracy: 0.4724\n",
            "Epoch 7/10\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.0797 - accuracy: 0.9950 - val_loss: 2.2030 - val_accuracy: 0.4596\n",
            "Epoch 8/10\n",
            "63/63 [==============================] - 5s 79ms/step - loss: 0.0525 - accuracy: 0.9995 - val_loss: 2.2195 - val_accuracy: 0.4715\n",
            "Epoch 9/10\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.0325 - accuracy: 1.0000 - val_loss: 2.3165 - val_accuracy: 0.4688\n",
            "Epoch 10/10\n",
            "63/63 [==============================] - 6s 90ms/step - loss: 0.0218 - accuracy: 1.0000 - val_loss: 2.2962 - val_accuracy: 0.4743\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f29146c7e80>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 凍結預訓練層\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# 模型訓練\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1JOp_biyQEZ"
      },
      "outputs": [],
      "source": [
        "# 後處理和植物資訊提供\n",
        "def predict_plant(image_path):\n",
        "    img = load_img(image_path, target_size=(224, 224))\n",
        "    img_array = img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array = img_array / 255.0\n",
        "\n",
        "    prediction = model.predict(img_array)\n",
        "    predicted_label = labels[np.argmax(prediction)]\n",
        "\n",
        "    # 使用 os.path.splitext 移除檔案名稱的擴展名\n",
        "    file_name = os.path.splitext(os.path.basename(image_path))[0]\n",
        "\n",
        "    # 輸出檔案名稱和預測結果\n",
        "    print(\"檔案名稱：\", file_name, \"_預測結果：\", predicted_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VggXnOG0yR9V",
        "outputId": "1e9f6287-5182-4e28-cca0-6610c81478a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "檔案名稱： tulip_tree_1 _預測結果： tulip_tree\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "檔案名稱： daisy_1 _預測結果： daisy\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "檔案名稱： elm_1 _預測結果： elm\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "檔案名稱： maple _預測結果： poison_ivy\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "檔案名稱： fig _預測結果： fig\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "檔案名稱： juniper _預測結果： juniper\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "檔案名稱： fern _預測結果： fir\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "檔案名稱： fir _預測結果： fir\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "檔案名稱： poison_ivy _預測結果： poison_ivy\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "檔案名稱： fern_1 _預測結果： elm\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "檔案名稱： maple_1 _預測結果： maple\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "檔案名稱： fir_1 _預測結果： fir\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "檔案名稱： dogwood_1 _預測結果： dogwood\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "檔案名稱： sycamore _預測結果： fig\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "檔案名稱： cyprus _預測結果： cyprus\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "檔案名稱： cattail_0 _預測結果： cattail\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "檔案名稱： dandelion _預測結果： dandelion\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "檔案名稱： fir_2 _預測結果： fir\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "檔案名稱： clover _預測結果： clover\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "檔案名稱： daisy _預測結果： daisy\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "檔案名稱： sycamore_1 _預測結果： sycamore\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "檔案名稱： cattail _預測結果： cattail\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "檔案名稱： elm _預測結果： elm\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "檔案名稱： dogwood _預測結果： dogwood\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "檔案名稱： sycamore_2 _預測結果： maple\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "檔案名稱： juniper_1 _預測結果： juniper\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "檔案名稱： trout_lily _預測結果： trout_lily\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "檔案名稱： tulip_tree _預測結果： tulip_tree\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "檔案名稱： cedar _預測結果： cedar\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "檔案名稱： poison_ivy_1 _預測結果： poison_ivy\n"
          ]
        }
      ],
      "source": [
        "# 測試\n",
        "test_images = os.listdir(test_path)\n",
        "for image_file in test_images:\n",
        "    image_path = os.path.join(test_path, image_file)\n",
        "    predict_plant(image_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEEvMMED2ece",
        "outputId": "fddeb280-5612-4c60-8bf2-9a4b1e44d087"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "準確率： 0.8333333333333334\n"
          ]
        }
      ],
      "source": [
        "# 創建一個字典，將標籤轉換為數字\n",
        "label_to_index = {label: i for i, label in enumerate(labels)}\n",
        "\n",
        "# 初始化計數器\n",
        "correct_predictions = 0\n",
        "total_predictions = 0\n",
        "\n",
        "# 計算準確率\n",
        "for image_file in test_images:\n",
        "    image_path = os.path.join(test_path, image_file)\n",
        "    img = load_img(image_path, target_size=(224, 224))\n",
        "    img_array = img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array = img_array / 255.0\n",
        "\n",
        "    # 進行預測\n",
        "    prediction = model.predict(img_array)\n",
        "    predicted_label = labels[np.argmax(prediction)]\n",
        "\n",
        "    # 獲取實際標籤\n",
        "    actual_label = image_file.split('.')[0]  # 去掉檔案名稱的擴展名\n",
        "\n",
        "    # 比較預測結果和實際標籤\n",
        "    if actual_label == predicted_label or actual_label.startswith(predicted_label):\n",
        "        correct_predictions += 1\n",
        "\n",
        "    total_predictions += 1\n",
        "\n",
        "# 計算並印出準確率\n",
        "accuracy = correct_predictions / total_predictions\n",
        "print(\"準確率：\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZD1fWx6joHoX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZ-jncKCx_A3"
      },
      "source": [
        "## Train model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTxC7KyXoHqh",
        "outputId": "70bdeb5a-b000-4f36-aa16-dfdf250b40e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9406464/9406464 [==============================] - 0s 0us/step\n",
            "Epoch 1/10\n",
            "63/62 [==============================] - ETA: 0s - loss: 2.4073 - accuracy: 0.3045\n",
            "Epoch 1: val_loss improved from inf to 2.33750, saving model to /content/drive/My Drive/colab/plant_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r62/62 [==============================] - 40s 530ms/step - loss: 2.4073 - accuracy: 0.3045 - val_loss: 2.3375 - val_accuracy: 0.2950 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "63/62 [==============================] - ETA: 0s - loss: 1.6164 - accuracy: 0.5260\n",
            "Epoch 2: val_loss improved from 2.33750 to 2.26522, saving model to /content/drive/My Drive/colab/plant_model.h5\n",
            "62/62 [==============================] - 28s 445ms/step - loss: 1.6164 - accuracy: 0.5260 - val_loss: 2.2652 - val_accuracy: 0.3557 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "63/62 [==============================] - ETA: 0s - loss: 1.4061 - accuracy: 0.5740\n",
            "Epoch 3: val_loss improved from 2.26522 to 2.09129, saving model to /content/drive/My Drive/colab/plant_model.h5\n",
            "62/62 [==============================] - 27s 432ms/step - loss: 1.4061 - accuracy: 0.5740 - val_loss: 2.0913 - val_accuracy: 0.4062 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "63/62 [==============================] - ETA: 0s - loss: 1.2581 - accuracy: 0.6125\n",
            "Epoch 4: val_loss did not improve from 2.09129\n",
            "62/62 [==============================] - 28s 444ms/step - loss: 1.2581 - accuracy: 0.6125 - val_loss: 2.1389 - val_accuracy: 0.4072 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "63/62 [==============================] - ETA: 0s - loss: 1.1066 - accuracy: 0.6600\n",
            "Epoch 5: val_loss improved from 2.09129 to 1.93509, saving model to /content/drive/My Drive/colab/plant_model.h5\n",
            "62/62 [==============================] - 29s 455ms/step - loss: 1.1066 - accuracy: 0.6600 - val_loss: 1.9351 - val_accuracy: 0.4577 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "63/62 [==============================] - ETA: 0s - loss: 1.0356 - accuracy: 0.6880\n",
            "Epoch 6: val_loss did not improve from 1.93509\n",
            "62/62 [==============================] - 28s 447ms/step - loss: 1.0356 - accuracy: 0.6880 - val_loss: 2.0729 - val_accuracy: 0.4301 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "63/62 [==============================] - ETA: 0s - loss: 0.9625 - accuracy: 0.7100\n",
            "Epoch 7: val_loss did not improve from 1.93509\n",
            "62/62 [==============================] - 28s 450ms/step - loss: 0.9625 - accuracy: 0.7100 - val_loss: 2.0858 - val_accuracy: 0.4237 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "63/62 [==============================] - ETA: 0s - loss: 0.9206 - accuracy: 0.7215\n",
            "Epoch 8: val_loss did not improve from 1.93509\n",
            "\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "62/62 [==============================] - 28s 441ms/step - loss: 0.9206 - accuracy: 0.7215 - val_loss: 2.2338 - val_accuracy: 0.4246 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "63/62 [==============================] - ETA: 0s - loss: 0.6996 - accuracy: 0.7925\n",
            "Epoch 9: val_loss did not improve from 1.93509\n",
            "62/62 [==============================] - 26s 419ms/step - loss: 0.6996 - accuracy: 0.7925 - val_loss: 2.0894 - val_accuracy: 0.4338 - lr: 2.0000e-04\n",
            "Epoch 10/10\n",
            "63/62 [==============================] - ETA: 0s - loss: 0.6524 - accuracy: 0.7995\n",
            "Epoch 10: val_loss did not improve from 1.93509\n",
            "62/62 [==============================] - 30s 469ms/step - loss: 0.6524 - accuracy: 0.7995 - val_loss: 2.0788 - val_accuracy: 0.4329 - lr: 2.0000e-04\n",
            "34/34 [==============================] - 2s 43ms/step\n",
            "混淆矩陣：\n",
            " [[18  6  0  0  2  2  0  0  1  3  0  0  1  0  0  4  1  5  0  1]\n",
            " [ 4 18  0  0  0  3  0  1  0  8  1  1  0  1  8 11  3 40  1  0]\n",
            " [ 0  0 26  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0]\n",
            " [ 2  0  0 23  1  2  0  4  0  2  0  0  3  2  2  1  2  5  0  0]\n",
            " [ 0  0  0  0 36  0  0  1  0  0  0  6  0  0  2  4  0  7  0  1]\n",
            " [ 1  6  0  0  1 16  0  0  0  0  1  0  4  2  1  0  0  8  0  1]\n",
            " [ 0  0  0  0  4  0 34  0  0  0  0  0  0  1  0  0  0  0  2  0]\n",
            " [ 0  0  2  0 10  0  2 72  0  2  0  1  2  0  4  2  0  3  0  0]\n",
            " [ 2  0  0  0  4  1  0  0 13  1  0  0  0  0  2  2  3  5  0  1]\n",
            " [ 1  0  0  0  2  0  0  0  0 13  0  0  0  0  2  4  1  9  0  0]\n",
            " [ 1  0  3  4  4  2  0  4  0  1 24  4  3  0  9  9  1  1  1  0]\n",
            " [ 0  4  2  0  1  0  0  0  0  1  0 10  0  0  2  2  0  4  1  1]\n",
            " [ 1  1  1  4  0  1  0  1  0  1  4  0 12  2  0  1  0  5  0  0]\n",
            " [ 0  0  0  2  0  9  0  0  0  3  2  1  0 11  0  0  2 13  0  0]\n",
            " [ 1  3  0  0  2  2  0  1  0  7  0  0  0  0 33  4 20 20  0  7]\n",
            " [ 1  0  1  1  1  0  0  4  0  1  0  0  0  0  7 56  5  5  1  3]\n",
            " [ 0  0  0  1  4  0  0  3  1  4  0  3  0  1 10  4 13  8  4  0]\n",
            " [ 1  0  1  1  1  0  0  0  1  3  0  3  0  0  8  3  5 27  1  1]\n",
            " [ 0  0  0  1  1  0  0  2  0  0  1  0  0  0  0  1  0  1 35  1]\n",
            " [ 2  2  0  0  0  0  0  0  1  2  0  1  0  0 17  5  2  5  0  8]]\n",
            "\n",
            "分類報告：\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         ash       0.51      0.41      0.46        44\n",
            "       beech       0.45      0.18      0.26       100\n",
            "     cattail       0.72      0.93      0.81        28\n",
            "       cedar       0.62      0.47      0.53        49\n",
            "      clover       0.49      0.63      0.55        57\n",
            "      cyprus       0.42      0.39      0.41        41\n",
            "       daisy       0.94      0.83      0.88        41\n",
            "   dandelion       0.77      0.72      0.75       100\n",
            "     dogwood       0.76      0.38      0.51        34\n",
            "         elm       0.25      0.41      0.31        32\n",
            "        fern       0.69      0.34      0.45        71\n",
            "         fig       0.33      0.36      0.34        28\n",
            "         fir       0.48      0.35      0.41        34\n",
            "     juniper       0.55      0.26      0.35        43\n",
            "       maple       0.31      0.33      0.32       100\n",
            "  poison_ivy       0.50      0.65      0.56        86\n",
            "    sweetgum       0.22      0.23      0.23        56\n",
            "    sycamore       0.16      0.48      0.24        56\n",
            "  trout_lily       0.76      0.81      0.79        43\n",
            "  tulip_tree       0.32      0.18      0.23        45\n",
            "\n",
            "    accuracy                           0.46      1088\n",
            "   macro avg       0.51      0.47      0.47      1088\n",
            "weighted avg       0.51      0.46      0.46      1088\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img, ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 設定檔案路徑\n",
        "data_path = \"/content/drive/My Drive/colab/PlantCLEF_Subset/PlantCLEF_Subset/\"\n",
        "train_path = data_path + \"train/\"\n",
        "val_path = data_path + \"val/\"\n",
        "test_path = data_path + \"test/\"\n",
        "label_file = data_path + \"labels.txt\"\n",
        "\n",
        "# 載入標籤\n",
        "with open(label_file, 'r') as file:\n",
        "    labels = [line.strip() for line in file]\n",
        "\n",
        "# 資料收集\n",
        "def load_data(directory, max_images=100):\n",
        "    data = []\n",
        "    labels = []\n",
        "    for label in os.listdir(directory):\n",
        "        label_path = os.path.join(directory, label)\n",
        "        count = 0\n",
        "        for filename in os.listdir(label_path):\n",
        "            if count >= max_images:\n",
        "                break\n",
        "            img_path = os.path.join(label_path, filename)\n",
        "            img = load_img(img_path, target_size=(224, 224))\n",
        "            img_array = img_to_array(img)\n",
        "            data.append(img_array)\n",
        "            labels.append(label)\n",
        "            count += 1\n",
        "    return np.array(data), np.array(labels)\n",
        "\n",
        "# 資料預處理\n",
        "def preprocess_data(data, labels):\n",
        "    data = data.astype('float') / 255.0\n",
        "    labels = LabelEncoder().fit_transform(labels)\n",
        "    labels = to_categorical(labels)\n",
        "    return data, labels\n",
        "\n",
        "# 加載訓練和驗證數據\n",
        "X_train, y_train = load_data(train_path)\n",
        "X_val, y_val = load_data(val_path)\n",
        "\n",
        "# 資料預處理\n",
        "X_train, y_train = preprocess_data(X_train, y_train)\n",
        "X_val, y_val = preprocess_data(X_val, y_val)\n",
        "\n",
        "# 資料增強\n",
        "datagen_train = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# 特徵提取 (使用MobileNetV2模型)\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "predictions = Dense(len(labels), activation='softmax')(x)\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# 凍結預訓練層\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# 模型訓練\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 設定回調函數\n",
        "checkpoint = ModelCheckpoint('/content/drive/My Drive/colab/plant_model.h5',\n",
        "                             monitor='val_loss',\n",
        "                             save_best_only=True,\n",
        "                             mode='min',\n",
        "                             verbose=1)\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
        "                              factor=0.2,\n",
        "                              patience=3,\n",
        "                              min_lr=0.0001,\n",
        "                              mode='min',\n",
        "                              verbose=1)\n",
        "\n",
        "# 訓練模型\n",
        "history = model.fit(datagen_train.flow(X_train, y_train, batch_size=32),\n",
        "                    steps_per_epoch=len(X_train) / 32,\n",
        "                    epochs=10,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    callbacks=[checkpoint, reduce_lr])\n",
        "\n",
        "# 載入最佳模型\n",
        "model.load_weights('/content/drive/My Drive/colab/plant_model.h5')\n",
        "\n",
        "# 混淆矩陣和分類報告\n",
        "y_pred = model.predict(X_val)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = np.argmax(y_val, axis=1)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_true, y_pred_classes)\n",
        "class_report = classification_report(y_true, y_pred_classes, target_names=labels)\n",
        "\n",
        "print(\"混淆矩陣：\\n\", conf_matrix)\n",
        "print(\"\\n分類報告：\\n\", class_report)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gmzt4Xjaspkd",
        "outputId": "22226eda-6c20-4063-8a81-b635bb05f2eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "測試集準確率： 0.8\n"
          ]
        }
      ],
      "source": [
        "# 計算測試集的準確率\n",
        "# 初始化計數器\n",
        "correct_predictions = 0\n",
        "total_predictions = 0\n",
        "\n",
        "# 計算準確率\n",
        "for image_file in os.listdir(test_path):\n",
        "    image_path = os.path.join(test_path, image_file)\n",
        "    img = load_img(image_path, target_size=(224, 224))\n",
        "    img_array = img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array = img_array / 255.0\n",
        "\n",
        "    # 進行預測\n",
        "    prediction = model.predict(img_array)\n",
        "    predicted_label = labels[np.argmax(prediction)]\n",
        "\n",
        "    # 獲取實際標籤\n",
        "    actual_label = image_file.split('.')[0]  # 去掉檔案名稱的擴展名\n",
        "\n",
        "    # 比較預測結果和實際標籤\n",
        "    if actual_label == predicted_label or actual_label.startswith(predicted_label):\n",
        "        correct_predictions += 1\n",
        "\n",
        "    total_predictions += 1\n",
        "\n",
        "# 計算並印出準確率\n",
        "accuracy = correct_predictions / total_predictions\n",
        "print(\"測試集準確率：\", accuracy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMDLA14N176s"
      },
      "source": [
        "## next"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1QpgyQ42Aws"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BwV7D1Sm2Ayr"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
